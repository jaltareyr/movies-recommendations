{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with importing some modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\movies-recommendations\\venv\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from nltk.stem import PorterStemmer\n",
    "import psycopg2\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data for movies metadata and associated keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"data/movies_metadata.csv\")\n",
    "keywords = pd.read_csv(\"data/keywords.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I am going to filter out low rated movies from my dataset. It won't make any sense to recommend movies to viewers if the movies are just not good even if there is high similarity scores.\n",
    "\n",
    "We will use IMDB formula to decide movie rating,\n",
    "\n",
    "$$ \n",
    "Weighted\\ Rating\\ (WR) =  \\left(\\frac{v}{v+m}\\right) R + \\left(\\frac{m}{v+m}\\right) C\n",
    "$$\n",
    "\n",
    "where,\n",
    "\n",
    "- v is the number of votes for the movie\n",
    "- m is the minimum votes required to be listed in the chart\n",
    "- R is the average rating of the movie\n",
    "- C is the mean vote across the whole report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v:  5.618207215134184 \n",
      "m:  34.0\n"
     ]
    }
   ],
   "source": [
    "metadata = metadata[metadata[\"vote_average\"].notna() == True]\n",
    "v = metadata[\"vote_count\"]\n",
    "C = metadata[\"vote_average\"].mean()\n",
    "\n",
    "vote_counts = metadata[\"vote_count\"].astype(int)\n",
    "\n",
    "m = vote_counts.quantile(0.75)\n",
    "\n",
    "# metadata = metadata[metadata[\"vote_count\"]>m]\n",
    "\n",
    "print(\"v: \", C, \"\\nm: \", m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "WR = (v/(v+m))*metadata[\"vote_average\"] + (m/(v+m))*C\n",
    "metadata[\"WR\"] = WR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying two data transformations,\n",
    "\n",
    "- stemming keywords before concatinating\n",
    "- dropping rows from keywords dataset if keywords are not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "def stemmer(ps_instance, word):\n",
    "    return ps_instance.stem(word)\n",
    "\n",
    "def getkeys(X):\n",
    "    if X ==[]:\n",
    "        return \"\"\n",
    "    keys = []\n",
    "    for key in X:\n",
    "        keys.append(stemmer(ps,key[\"name\"]))\n",
    "    return \",\".join(keys)\n",
    "\n",
    "keywords[\"keywords\"] = keywords[\"keywords\"].astype(str).apply(literal_eval)\n",
    "keywords[\"keywords\"] = keywords[\"keywords\"].apply(getkeys)\n",
    "keywords = keywords[keywords[\"keywords\"].replace(\"\", pd.NA).notna()]\n",
    "keywords[\"id\"] = keywords[\"id\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will work on the movies_metadata to only retain required columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = metadata[[ \"imdb_id\", \"id\", \"genres\", \"original_language\", \"original_title\", \"overview\", \"tagline\", \"title\", \"WR\"]]\n",
    "movies[\"id\"] = movies[\"id\"].astype(str)\n",
    "movies = pd.merge(movies, keywords, on='id', how='left')\n",
    "\n",
    "del metadata\n",
    "del keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGenres(X):\n",
    "    genres = []\n",
    "    for genre in X:\n",
    "        # genres.append(stemmer(ps,genre[\"name\"]))\n",
    "        genres.append(genre[\"name\"].lower())\n",
    "    return genres\n",
    "\n",
    "movies[\"genres\"] = movies[\"genres\"].apply(literal_eval).apply(getGenres)\n",
    "\n",
    "movies = movies[movies[\"overview\"].notna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applied One-Hot encoding to genres, I found that there are in total 21 genres in my movies dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "genres_one_hot = pd.DataFrame(mlb.fit_transform(movies[\"genres\"]), columns=mlb.classes_, index=movies.index)\n",
    "genres_encoded = pd.concat([movies['id'], genres_one_hot], axis=1)\n",
    "\n",
    "movies[\"embd_genres\"] = genres_encoded[['action', 'adventure', 'animation', 'comedy', 'crime',\n",
    "       'documentary', 'drama', 'family', 'fantasy', 'foreign', 'history',\n",
    "       'horror', 'music', 'mystery', 'romance', 'science fiction', 'thriller',\n",
    "       'tv movie', 'war', 'western']].apply(lambda row: list(row), axis=1)\n",
    "\n",
    "embeddings = pd.concat([movies[\"id\"], movies[\"embd_genres\"]],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, my data is ready! I am going to insert all embeddings in a PostgreSQL database, where I have enabled vector storage by installing pgvector extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to interrupt the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.12.6)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def encode(X):\n",
    "    try:\n",
    "        return model.encode(X)\n",
    "    except:\n",
    "        return model.encode(\"\")\n",
    "    \n",
    "# docker inspect -f '{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}' pgvector-container\n",
    "  \n",
    "conn = psycopg2.connect(\n",
    "  database=\"projects\",\n",
    "  user=\"postgres\",\n",
    "  password=\"Podcast@321\",\n",
    "  host=\"127.0.0.1\",\n",
    "  port=5432\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "for row in range(movies.shape[0]):\n",
    "\n",
    "    id = movies.iloc[row][\"id\"]\n",
    "\n",
    "    title = str(movies.iloc[row][\"title\"])\n",
    "\n",
    "    wr = movies.iloc[row][\"WR\"]\n",
    "\n",
    "    embd_overview = encode(movies.iloc[row][\"overview\"])\n",
    "    embd_overview_str = \"[{}]\".format(\",\".join(map(str, embd_overview)))\n",
    "\n",
    "    embd_tagline = encode(movies.iloc[row][\"tagline\"])\n",
    "    embd_tagline_str = \"[{}]\".format(\",\".join(map(str, embd_tagline)))\n",
    "\n",
    "    embd_keywords = encode(movies.iloc[row][\"keywords\"])\n",
    "    embd_keywords_str = \"[{}]\".format(\",\".join(map(str, embd_keywords)))\n",
    "\n",
    "    embd_genres = embeddings.iloc[row][\"embd_genres\"]\n",
    "    embd_genres_str = \"[{}]\".format(\",\".join(map(str, embd_genres)))\n",
    "\n",
    "    try:\n",
    "        cursor.execute(\"\"\"INSERT INTO movies_recommend.embeddings (id,\n",
    "                        embd_overview,\n",
    "                        embd_tagline,\n",
    "                        embd_keywords,\n",
    "                        embd_genres) \n",
    "                        VALUES (%s, %s, %s, %s,%s)\"\"\",(id, embd_overview_str, embd_tagline_str, embd_keywords_str, embd_genres_str))\n",
    "    \n",
    "        cursor.execute(\"\"\"INSERT INTO movies_recommend.movies(id,\n",
    "                        title,\n",
    "                        weighted_rating)\n",
    "                        VALUES (%s, %s, %s)\"\"\", (id, title, str(wr)))\n",
    "    except psycopg2.Error as e:\n",
    "        print(f\"Error inserting row {row}: {e}\")\n",
    "        conn.rollback()\n",
    "\n",
    "    if row%1000 == 0:\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select base_movie, id, title, 1-cosine_distance as cosine_similarity\n",
    "# from (\n",
    "# select b.title as base_movie, a.id, a.title, a.embd_overview <-> b.embd_overview as cosine_distance\n",
    "# from movies_recommend.embeddings a\n",
    "# left join movies_recommend.embeddings b\n",
    "# on 1=1\n",
    "# and b.id = 216015\n",
    "# )\n",
    "# order by cosine_similarity desc\n",
    "# limit 50;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
